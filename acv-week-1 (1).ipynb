{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":1335230,"datasetId":775382,"databundleVersionId":1367557,"isSourceIdPinned":false}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\npath = kagglehub.dataset_download(\"tschandl/isic2018-challenge-task1-data-segmentation\")\n\nprint(\"Path to dataset files:\", path)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T05:00:35.155264Z","iopub.execute_input":"2026-02-18T05:00:35.155606Z","iopub.status.idle":"2026-02-18T05:00:36.099204Z","shell.execute_reply.started":"2026-02-18T05:00:35.155580Z","shell.execute_reply":"2026-02-18T05:00:36.098350Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/datasets/tschandl/isic2018-challenge-task1-data-segmentation\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom glob import glob\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# KaggleHub dataset path\nBASE_DIR = \"/kaggle/input/datasets/tschandl/isic2018-challenge-task1-data-segmentation\"\n\nprint(\"Available folders:\")\nprint(os.listdir(BASE_DIR))\n\nTRAIN_IMG_DIR = os.path.join(BASE_DIR, \"ISIC2018_Task1-2_Training_Input\")\nTRAIN_MASK_DIR = os.path.join(BASE_DIR, \"ISIC2018_Task1_Training_GroundTruth\")\n\nprint(\"Image path exists:\", os.path.exists(TRAIN_IMG_DIR))\nprint(\"Mask path exists:\", os.path.exists(TRAIN_MASK_DIR))\n\nIMG_SIZE = 224\nBATCH_SIZE = 4\nLR = 1e-4\nEPOCHS = 15\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(\"Using device:\", DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T05:00:36.100799Z","iopub.execute_input":"2026-02-18T05:00:36.101530Z","iopub.status.idle":"2026-02-18T05:00:41.685000Z","shell.execute_reply.started":"2026-02-18T05:00:36.101494Z","shell.execute_reply":"2026-02-18T05:00:41.684143Z"}},"outputs":[{"name":"stdout","text":"Available folders:\n['ISIC2018_Task1-2_Training_Input', 'ISIC2018_Task1_Training_GroundTruth', 'ISIC2018_Task1-2_Test_Input', 'ISIC2018_Task1-2_Validation_Input']\nImage path exists: True\nMask path exists: True\nUsing device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class ISICDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, transform=None):\n        self.image_paths = sorted(glob(os.path.join(image_dir, \"*.jpg\")))\n        self.mask_dir = mask_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        filename = os.path.basename(img_path).replace(\".jpg\", \"_segmentation.png\")\n        mask_path = os.path.join(self.mask_dir, filename)\n\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n\n        if self.transform:\n            augmented = self.transform(image=image, mask=mask)\n            image = augmented[\"image\"]\n            mask = augmented[\"mask\"]\n\n        mask = mask.unsqueeze(0).float() / 255.0\n\n        return image, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T05:00:41.686058Z","iopub.execute_input":"2026-02-18T05:00:41.686523Z","iopub.status.idle":"2026-02-18T05:00:41.693120Z","shell.execute_reply.started":"2026-02-18T05:00:41.686496Z","shell.execute_reply":"2026-02-18T05:00:41.692350Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"transform = A.Compose([\n    A.Resize(IMG_SIZE, IMG_SIZE),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.3),\n    A.Normalize(),\n    ToTensorV2(),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T05:00:41.694281Z","iopub.execute_input":"2026-02-18T05:00:41.694773Z","iopub.status.idle":"2026-02-18T05:00:41.708840Z","shell.execute_reply.started":"2026-02-18T05:00:41.694746Z","shell.execute_reply":"2026-02-18T05:00:41.708065Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def dice_loss(pred, target, smooth=1):\n    pred = torch.sigmoid(pred)\n    intersection = (pred * target).sum()\n    dice = (2 * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n    return 1 - dice\n\n\nclass DiceBCELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bce = nn.BCEWithLogitsLoss()\n\n    def forward(self, pred, target):\n        return self.bce(pred, target) + dice_loss(pred, target)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T05:00:41.710719Z","iopub.execute_input":"2026-02-18T05:00:41.711426Z","iopub.status.idle":"2026-02-18T05:00:41.718974Z","shell.execute_reply.started":"2026-02-18T05:00:41.711392Z","shell.execute_reply":"2026-02-18T05:00:41.717970Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"dataset = ISICDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\nprint(\"Train samples:\", len(train_dataset))\nprint(\"Validation samples:\", len(val_dataset))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T05:00:41.720011Z","iopub.execute_input":"2026-02-18T05:00:41.720370Z","iopub.status.idle":"2026-02-18T05:00:41.786674Z","shell.execute_reply.started":"2026-02-18T05:00:41.720311Z","shell.execute_reply":"2026-02-18T05:00:41.785988Z"}},"outputs":[{"name":"stdout","text":"Train samples: 2075\nValidation samples: 519\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass UNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.enc1 = DoubleConv(3, 64)\n        self.enc2 = DoubleConv(64, 128)\n        self.enc3 = DoubleConv(128, 256)\n        self.enc4 = DoubleConv(256, 512)\n\n        self.pool = nn.MaxPool2d(2)\n        self.bottleneck = DoubleConv(512, 1024)\n\n        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n        self.dec4 = DoubleConv(1024, 512)\n\n        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n        self.dec3 = DoubleConv(512, 256)\n\n        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n        self.dec2 = DoubleConv(256, 128)\n\n        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.dec1 = DoubleConv(128, 64)\n\n        self.final = nn.Conv2d(64, 1, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        e4 = self.enc4(self.pool(e3))\n\n        b = self.bottleneck(self.pool(e4))\n\n        d4 = self.up4(b)\n        d4 = torch.cat([d4, e4], dim=1)\n        d4 = self.dec4(d4)\n\n        d3 = self.up3(d4)\n        d3 = torch.cat([d3, e3], dim=1)\n        d3 = self.dec3(d3)\n\n        d2 = self.up2(d3)\n        d2 = torch.cat([d2, e2], dim=1)\n        d2 = self.dec2(d2)\n\n        d1 = self.up1(d2)\n        d1 = torch.cat([d1, e1], dim=1)\n        d1 = self.dec1(d1)\n\n        return self.final(d1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T05:00:41.787465Z","iopub.execute_input":"2026-02-18T05:00:41.787688Z","iopub.status.idle":"2026-02-18T05:00:41.798758Z","shell.execute_reply.started":"2026-02-18T05:00:41.787667Z","shell.execute_reply":"2026-02-18T05:00:41.797864Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def dice_loss(pred, target, smooth=1):\n    pred = torch.sigmoid(pred)\n    intersection = (pred * target).sum()\n    dice = (2 * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n    return 1 - dice\n\n\nclass DiceBCELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bce = nn.BCEWithLogitsLoss()\n\n    def forward(self, pred, target):\n        return self.bce(pred, target) + dice_loss(pred, target)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T05:00:41.799755Z","iopub.execute_input":"2026-02-18T05:00:41.800031Z","iopub.status.idle":"2026-02-18T05:00:41.813239Z","shell.execute_reply.started":"2026-02-18T05:00:41.800008Z","shell.execute_reply":"2026-02-18T05:00:41.812376Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dataset = ISICDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform)\n\nprint(\"Total images found:\", len(dataset))\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=0   # important for stability\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    num_workers=0\n)\n\nprint(\"Train samples:\", len(train_dataset))\nprint(\"Validation samples:\", len(val_dataset))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T05:00:41.814417Z","iopub.execute_input":"2026-02-18T05:00:41.814697Z","iopub.status.idle":"2026-02-18T05:00:41.838430Z","shell.execute_reply.started":"2026-02-18T05:00:41.814673Z","shell.execute_reply":"2026-02-18T05:00:41.837577Z"}},"outputs":[{"name":"stdout","text":"Total images found: 2594\nTrain samples: 2075\nValidation samples: 519\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model = UNet().to(DEVICE)\noptimizer = optim.Adam(model.parameters(), lr=LR)\ncriterion = DiceBCELoss()\n\nfor epoch in range(EPOCHS):\n    torch.cuda.empty_cache()\n\n    # -------- TRAINING --------\n    model.train()\n    train_loss = 0\n\n    for images, masks in tqdm(train_loader):\n        images = images.to(DEVICE)\n        masks = masks.to(DEVICE)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, masks)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    train_loss /= len(train_loader)\n\n    # -------- VALIDATION --------\n    model.eval()\n\n    dice_score = 0\n    iou_score = 0\n\n    TP = 0\n    FP = 0\n    FN = 0\n    TN = 0\n\n    with torch.no_grad():\n        for images, masks in val_loader:\n            images = images.to(DEVICE)\n            masks = masks.to(DEVICE)\n\n            outputs = torch.sigmoid(model(images))\n            outputs = (outputs > 0.5).float()\n\n            # Flatten tensors\n            outputs_flat = outputs.view(-1)\n            masks_flat = masks.view(-1)\n\n            # Confusion components\n            tp = (outputs_flat * masks_flat).sum()\n            fp = (outputs_flat * (1 - masks_flat)).sum()\n            fn = ((1 - outputs_flat) * masks_flat).sum()\n            tn = ((1 - outputs_flat) * (1 - masks_flat)).sum()\n\n            TP += tp.item()\n            FP += fp.item()\n            FN += fn.item()\n            TN += tn.item()\n\n            # Dice & IoU\n            intersection = tp\n            union = tp + fp + fn\n\n            dice = (2 * intersection) / (2 * intersection + fp + fn + 1e-8)\n            iou = intersection / (union + 1e-8)\n\n            dice_score += dice.item()\n            iou_score += iou.item()\n\n    dice_score /= len(val_loader)\n    iou_score /= len(val_loader)\n\n    # Derived metrics\n    pixel_accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-8)\n    precision = TP / (TP + FP + 1e-8)\n    recall = TP / (TP + FN + 1e-8)          # Sensitivity\n    specificity = TN / (TN + FP + 1e-8)\n\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    print(f\"Train Loss: {train_loss:.4f}\")\n    print(f\"Val Dice: {dice_score:.4f}\")\n    print(f\"Val IoU: {iou_score:.4f}\")\n    print(f\"Pixel Acc: {pixel_accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall (Sensitivity): {recall:.4f}\")\n    print(f\"Specificity: {specificity:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T05:00:41.839556Z","iopub.execute_input":"2026-02-18T05:00:41.840024Z","iopub.status.idle":"2026-02-18T07:13:43.149000Z","shell.execute_reply.started":"2026-02-18T05:00:41.839941Z","shell.execute_reply":"2026-02-18T07:13:43.148237Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 519/519 [08:46<00:00,  1.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/15\nTrain Loss: 0.8999\nVal Dice: 0.7390\nVal IoU: 0.6082\nPixel Acc: 0.8794\nPrecision: 0.6782\nRecall (Sensitivity): 0.8161\nSpecificity: 0.8963\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:15<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/15\nTrain Loss: 0.6376\nVal Dice: 0.8023\nVal IoU: 0.6840\nPixel Acc: 0.9190\nPrecision: 0.7897\nRecall (Sensitivity): 0.8401\nSpecificity: 0.9401\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:14<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/15\nTrain Loss: 0.5450\nVal Dice: 0.8220\nVal IoU: 0.7079\nPixel Acc: 0.9323\nPrecision: 0.8858\nRecall (Sensitivity): 0.7801\nSpecificity: 0.9731\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:11<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/15\nTrain Loss: 0.4709\nVal Dice: 0.7939\nVal IoU: 0.6750\nPixel Acc: 0.9168\nPrecision: 0.8156\nRecall (Sensitivity): 0.7831\nSpecificity: 0.9526\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:12<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/15\nTrain Loss: 0.4203\nVal Dice: 0.8339\nVal IoU: 0.7275\nPixel Acc: 0.9390\nPrecision: 0.9440\nRecall (Sensitivity): 0.7562\nSpecificity: 0.9880\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:13<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/15\nTrain Loss: 0.3932\nVal Dice: 0.8444\nVal IoU: 0.7418\nPixel Acc: 0.9408\nPrecision: 0.9086\nRecall (Sensitivity): 0.8000\nSpecificity: 0.9785\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:08<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/15\nTrain Loss: 0.3704\nVal Dice: 0.8514\nVal IoU: 0.7530\nPixel Acc: 0.9427\nPrecision: 0.8896\nRecall (Sensitivity): 0.8320\nSpecificity: 0.9724\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:12<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/15\nTrain Loss: 0.3499\nVal Dice: 0.8353\nVal IoU: 0.7307\nPixel Acc: 0.9393\nPrecision: 0.9235\nRecall (Sensitivity): 0.7769\nSpecificity: 0.9828\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:13<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/15\nTrain Loss: 0.3399\nVal Dice: 0.8612\nVal IoU: 0.7641\nPixel Acc: 0.9459\nPrecision: 0.8906\nRecall (Sensitivity): 0.8481\nSpecificity: 0.9721\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:13<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/15\nTrain Loss: 0.3422\nVal Dice: 0.8550\nVal IoU: 0.7578\nPixel Acc: 0.9448\nPrecision: 0.9368\nRecall (Sensitivity): 0.7923\nSpecificity: 0.9857\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:14<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11/15\nTrain Loss: 0.3244\nVal Dice: 0.8497\nVal IoU: 0.7472\nPixel Acc: 0.9410\nPrecision: 0.8640\nRecall (Sensitivity): 0.8554\nSpecificity: 0.9640\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:14<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12/15\nTrain Loss: 0.3259\nVal Dice: 0.8691\nVal IoU: 0.7776\nPixel Acc: 0.9512\nPrecision: 0.9385\nRecall (Sensitivity): 0.8228\nSpecificity: 0.9856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:14<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13/15\nTrain Loss: 0.3255\nVal Dice: 0.8635\nVal IoU: 0.7698\nPixel Acc: 0.9478\nPrecision: 0.9140\nRecall (Sensitivity): 0.8313\nSpecificity: 0.9790\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:10<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14/15\nTrain Loss: 0.3105\nVal Dice: 0.8516\nVal IoU: 0.7537\nPixel Acc: 0.9444\nPrecision: 0.9530\nRecall (Sensitivity): 0.7748\nSpecificity: 0.9898\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 519/519 [07:14<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15/15\nTrain Loss: 0.3069\nVal Dice: 0.8684\nVal IoU: 0.7753\nPixel Acc: 0.9488\nPrecision: 0.8886\nRecall (Sensitivity): 0.8659\nSpecificity: 0.9709\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"torch.save({\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n}, \"unet_isic_checkpoint.pth\")\n\nprint(\"Checkpoint saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T07:13:43.150090Z","iopub.execute_input":"2026-02-18T07:13:43.150604Z","iopub.status.idle":"2026-02-18T07:13:43.750528Z","shell.execute_reply.started":"2026-02-18T07:13:43.150575Z","shell.execute_reply":"2026-02-18T07:13:43.749851Z"}},"outputs":[{"name":"stdout","text":"Checkpoint saved.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('/kaggle/working/unet_isic_checkpoint.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T07:41:34.862369Z","iopub.execute_input":"2026-02-18T07:41:34.862723Z","iopub.status.idle":"2026-02-18T07:41:34.875367Z","shell.execute_reply.started":"2026-02-18T07:41:34.862694Z","shell.execute_reply":"2026-02-18T07:41:34.874660Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/unet_isic_checkpoint.pth","text/html":"<a href='/kaggle/working/unet_isic_checkpoint.pth' target='_blank'>/kaggle/working/unet_isic_checkpoint.pth</a><br>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"!zip model_checkpoint.zip /kaggle/working/unet_isic_checkpoint.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T07:50:22.330081Z","iopub.execute_input":"2026-02-18T07:50:22.330859Z","iopub.status.idle":"2026-02-18T07:50:43.969343Z","shell.execute_reply.started":"2026-02-18T07:50:22.330829Z","shell.execute_reply":"2026-02-18T07:50:43.968566Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/unet_isic_checkpoint.pth (deflated 8%)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from IPython.display import FileLink\ndisplay(FileLink('model_checkpoint.zip'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T07:51:34.281365Z","iopub.execute_input":"2026-02-18T07:51:34.282096Z","iopub.status.idle":"2026-02-18T07:51:34.287757Z","shell.execute_reply.started":"2026-02-18T07:51:34.282063Z","shell.execute_reply":"2026-02-18T07:51:34.286963Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_checkpoint.zip","text/html":"<a href='model_checkpoint.zip' target='_blank'>model_checkpoint.zip</a><br>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tkinter import Tk\nfrom tkinter.filedialog import askopenfilename\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nIMG_SIZE = 224  # Must match training size\n\n\n# ---------- U-Net Architecture (Must Match Training) ----------\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass UNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.enc1 = DoubleConv(3, 64)\n        self.enc2 = DoubleConv(64, 128)\n        self.enc3 = DoubleConv(128, 256)\n        self.enc4 = DoubleConv(256, 512)\n\n        self.pool = nn.MaxPool2d(2)\n        self.bottleneck = DoubleConv(512, 1024)\n\n        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n        self.dec4 = DoubleConv(1024, 512)\n\n        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n        self.dec3 = DoubleConv(512, 256)\n\n        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n        self.dec2 = DoubleConv(256, 128)\n\n        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.dec1 = DoubleConv(128, 64)\n\n        self.final = nn.Conv2d(64, 1, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        e4 = self.enc4(self.pool(e3))\n\n        b = self.bottleneck(self.pool(e4))\n\n        d4 = self.up4(b)\n        d4 = torch.cat([d4, e4], dim=1)\n        d4 = self.dec4(d4)\n\n        d3 = self.up3(d4)\n        d3 = torch.cat([d3, e3], dim=1)\n        d3 = self.dec3(d3)\n\n        d2 = self.up2(d3)\n        d2 = torch.cat([d2, e2], dim=1)\n        d2 = self.dec2(d2)\n\n        d1 = self.up1(d2)\n        d1 = torch.cat([d1, e1], dim=1)\n        d1 = self.dec1(d1)\n\n        return self.final(d1)\n\n\n# ---------- Load Model ----------\n\nmodel = UNet().to(DEVICE)\n\ncheckpoint_path = r\"C:\\Users\\dines\\Downloads\\model_checkpoint (1)\\kaggle\\working\\unet_isic_checkpoint.pth\"\n\ncheckpoint = torch.load(checkpoint_path, map_location=DEVICE)\nmodel.load_state_dict(checkpoint['model_state_dict'])\n\nmodel.eval()\n\nprint(\"Model loaded successfully.\")\n\n\n# ---------- Select Image From PC ----------\n\nTk().withdraw()\nimage_path = askopenfilename(title=\"Select Skin Image\")\n\nif image_path == \"\":\n    print(\"No image selected.\")\n    exit()\n\nprint(\"Selected image:\", image_path)\n\n\n# ---------- Preprocess Image ----------\n\nimage = cv2.imread(image_path)\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\noriginal_image = image_rgb.copy()\n\nimage_resized = cv2.resize(image_rgb, (IMG_SIZE, IMG_SIZE))\nimage_norm = image_resized / 255.0\n\nimage_tensor = torch.tensor(image_norm, dtype=torch.float32)\nimage_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0).to(DEVICE)\n\n\n# ---------- Predict ----------\n\nwith torch.no_grad():\n    output = torch.sigmoid(model(image_tensor))\n    mask = (output > 0.5).float()\n\nmask = mask.squeeze().cpu().numpy()\n\n\n# ---------- Display Results ----------\n\nplt.figure(figsize=(12,4))\n\nplt.subplot(1,3,1)\nplt.title(\"Original\")\nplt.imshow(original_image)\nplt.axis(\"off\")\n\nplt.subplot(1,3,2)\nplt.title(\"Predicted Mask\")\nplt.imshow(mask, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1,3,3)\nplt.title(\"Overlay\")\nplt.imshow(original_image)\nplt.imshow(mask, cmap=\"jet\", alpha=0.4)\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T07:01:48.154345Z","iopub.execute_input":"2026-02-23T07:01:48.155143Z","iopub.status.idle":"2026-02-23T07:01:48.431835Z","shell.execute_reply.started":"2026-02-23T07:01:48.155109Z","shell.execute_reply":"2026-02-23T07:01:48.430940Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/150048323.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"C:\\Users\\dines\\Downloads\\model_checkpoint (1)\\kaggle\\working\\unet_isic_checkpoint.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\dines\\\\Downloads\\\\model_checkpoint (1)\\\\kaggle\\\\working\\\\unet_isic_checkpoint.pth'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'C:\\\\Users\\\\dines\\\\Downloads\\\\model_checkpoint (1)\\\\kaggle\\\\working\\\\unet_isic_checkpoint.pth'","output_type":"error"}],"execution_count":4}]}